{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Selection for Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is an optional assignment that will not be graded. It is an opportunity for you to gain a deeper understanding of nearest neighbor and to put your creativity to work.**\n",
    "\n",
    "One way to speed up nearest neighbor classification is to replace the training set by a carefully chosen\n",
    "subset. The selected training points can be thought of as **prototypes**.\n",
    "\n",
    "In this notebook you will <font color=\"blue\">*create your own strategy*</font> for selecting prototypes for nearest neighbor classification. You will apply this to the **MNIST** dataset. You will then see how your prototypes compare to a *random* subset of training points of the same size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the **entire** `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    # Read the inputs in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data / np.float32(256)\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        #data2 = np.zeros( (len(data),10), dtype=np.float32 )\n",
    "        #for i in range(len(data)):\n",
    "        #    data2[i][ data[i] ] = 1.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now import the required packages and load in `MNIST`. If necessary, `MNIST` is downloaded onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choosing prototypes at random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you a better idea of how this process works, let's first consider the case where the prototypes are chosen at random from the training set. We will set the number of prototypes to $M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function, <font color=\"blue\">**rand_prototypes**</font>, returns an array of $M$ points chosen randomly form the training set, along with a second array containing their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_prototypes(M):\n",
    "    indices = np.random.choice( len(train_labels) , M, replace=False)\n",
    "    return train_data[indices,:], train_labels[indices] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of **rand_prototypes** in action, with $M = 1000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data, example_labels = rand_prototypes(1000)\n",
    "print(\"Shape of train_data:\", train_data.shape)\n",
    "print(\"Shape of array of prototypes: \", example_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the error rate obtained on the MNIST test set (of 10,000 points) when nearest neighbor classification is performed using a set of prototypes returned by the **rand_prototypes** function. Intuitively, we would expect the error rate to go down as more prototypes are used: that is, as $M$ increases.\n",
    "\n",
    "The function, <font color=\"blue\">**NN_error**</font>,  computes the MNIST test error when using 1-NN classification with a specified set of prototypes (and their labels). To speed up the computation, a *ball tree* data strcutre is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_error(proto_data, proto_labels):\n",
    "    ball_tree = BallTree(proto_data, metric='euclidean')\n",
    "    test_neighbors = np.squeeze(ball_tree.query(test_data, k=1, return_distance=False))\n",
    "    test_fit = proto_labels[test_neighbors]\n",
    "    return sum(test_fit != test_labels)/float(len(test_fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any specific value of $M$, different random choices of the prototypes may yield different error rates. Thus, it only makes sense to talk about the **mean** error rate for a specific value of $M$. We can estimate this mean value by drawing *several* random subsets of $M$ prototypes, computing the test error with each, and then taking their average. \n",
    "\n",
    "The following function does this, using $k$ random sets of prototypes. It also returns a crude bound on the standard deviation of the estimated mean: the standard deviation of the $k$ error values, divided by sqrt(k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_error(fn_strategy, M, k=1):\n",
    "    errors = np.zeros(k)\n",
    "    for i in range(0,k):\n",
    "        proto_data, proto_labels = fn_strategy(M)\n",
    "        errors[i] = NN_error(proto_data, proto_labels) \n",
    "    return np.mean(errors), np.std(errors)/np.sqrt(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use **mean_error** to get error rates (and standard deviations) for a few different values of $M$. \n",
    "\n",
    "**Warning:** This will take some time, maybe half an hour or more. If you don't want to wait, choose a smaller value of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_values = [1000, 2000, 3000, 4000, 5000]\n",
    "errors = np.zeros(5)\n",
    "errorbars = np.zeros(5)\n",
    "k = 5\n",
    "for i in range(0, len(errors)):\n",
    "    errors[i], errorbars[i] = mean_error(rand_prototypes, M_values[i], k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot these values, along with errorbars (twice the standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(np.linspace(1000,5000,5), errors, yerr=errorbars*2.0, fmt='-o')\n",
    "plt.xlabel('Number of prototypes (M)', fontsize=14)\n",
    "plt.ylabel('Mean error', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Design your own prototype selection algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time for you to suggest your own strategy for picking a set of $M$ prototypes that will be used as the basis for 1-NN classification. \n",
    "\n",
    "Write a function, <font color=\"blue\">**my_prototypes**</font>, that creates a set of $M$ prototypes, using a strategy of your choosing. Like the the **rand_prototypes** function, your function should take $M$ as input and should return two arrays: the prototypes themselves, and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this Cell\n",
    "\n",
    "def my_prototypes(M):\n",
    "    \n",
    "    # \n",
    "    # Write your own function here\n",
    "    #\n",
    "    \n",
    "    return prototype_data, prototype_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to put your code to the test! Let's see if it can do better than selecting prototypes at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following widget to see how your code fares against the random strategy by moving the sliders around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual( M=(100,2000,100), rounds=(1,10))\n",
    "def comparison(M,rounds):\n",
    "    print(\"Comparing your prototype selection method to random prototype selection...\")\n",
    "    rand_err, rand_std = mean_error(rand_prototypes, M, rounds) \n",
    "    my_err, my_std   = mean_error(  my_prototypes, M, rounds) \n",
    "    \n",
    "    print;print(\"Number of prototypes:\", M)\n",
    "    print(\"Number of trials:\", rounds)\n",
    "    print(\"Error for random prototypes:\", rand_err )\n",
    "    print(\"Error for your prototypes:\", my_err );print\n",
    "    if rand_err < my_err:\n",
    "        print(\"RANDOM prototypes win!\")\n",
    "    else:\n",
    "        print(\"YOUR prototypes win!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "state": {
    "073fc6c098624989b84aa34a1c3a0246": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
